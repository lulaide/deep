{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d39b771",
   "metadata": {},
   "source": [
    "实验任务19：对随机生成的数据进行层归一化，使其均值为0且方差为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0668cdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输出：\n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "均值:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "方差:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n",
      "层归一化后的输出:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "均值:\n",
      " tensor([[2.9802e-08],\n",
      "        [3.9736e-08]], grad_fn=<MeanBackward1>)\n",
      "方差:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 随机生成两个训练样本，每个样本包含5个维度\n",
    "batch_example = torch.randn(2, 5) \n",
    "# 实现一个具有5个输入和6个输出的神经网络层\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"原始输出：\\n\", out)\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"均值:\\n\", mean)\n",
    "print(\"方差:\\n\", var)\n",
    "\n",
    "# 数据减去均值并除以方差实现归一化\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"层归一化后的输出:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"均值:\\n\", mean)\n",
    "print(\"方差:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c9eba",
   "metadata": {},
   "source": [
    "实验任务20：将层归一化封装成Pytorch模块以便后续用于GPT模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23e0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d01571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试层归一化模块\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09970ee0",
   "metadata": {},
   "source": [
    "实验任务21：实现具有GELU激活函数的前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792ff41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELU激活函数实现\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a55f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前馈神经网络模块实现\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe51771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# 测试前馈神经网络模块\n",
    "# 通过Python字典指定小型GPT-2模型配置以便后续使用\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # 词汇表大小\n",
    "    \"context_length\": 1024, # 上下文长度\n",
    "    \"emb_dim\": 768,         # 嵌入维度\n",
    "    \"n_heads\": 12,          # 注意力头数\n",
    "    \"n_layers\": 12,         # 层数\n",
    "    \"drop_rate\": 0.1,       # Dropout率\n",
    "    \"qkv_bias\": False       # 查询-键-值偏置\n",
    "}\n",
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# 输入数据的维度: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768) \n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62805c42",
   "metadata": {},
   "source": [
    "实验任务22：实现Tranformer模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604ee4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入上一节课实现的多头注意力机制模块\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\" # 输出维度是头数量的倍数\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads \n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # 增加一个线性层合并多头注意力的输出结果（可选的操作）\n",
    "        self.out_proj = nn.Linear(d_out, d_out) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x) # 维度: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        # 在原始张量的基础上增加一个多头维度，实现隐式划分矩阵\n",
    "        # 展开最后一个维度: (b, num_tokens, d_out) -> \n",
    "        # (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        # 张量转置:(b, num_tokens, num_heads, head_dim) -> \n",
    "        # (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # 每个头实现内积\n",
    "        #实现因果掩码\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # 张量维度: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        # 拼接多个头的输出 self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91b0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现Transformer模块\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 增加快捷连接\n",
    "        shortcut = x\n",
    "        x = self.norm1(x) #层归一化\n",
    "        x = self.att(x)  # 多头注意力机制，数据维度：[batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x) #dropout\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # 为前馈神经网络增加快捷连接\n",
    "        shortcut = x\n",
    "        x = self.norm2(x) \n",
    "        x = self.ff(x) # 前馈神经网络\n",
    "        x = self.drop_shortcut(x) ##dropout\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1398e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "# 测试Transformer模块\n",
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a1aa51",
   "metadata": {},
   "source": [
    "实验任务23：基于Transformer模块构建并初始化一个GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc16dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现GPT模型\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        # 堆叠多个Transformer模块，堆叠层数为配置文件中定义的n_layers\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        # 输入到线性层之前进行层归一化\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        # 线性层的输出是词汇表大小\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) \n",
    "        x = tok_embeds + pos_embeds  # 维度 [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbaf5249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "输出数据维度: torch.Size([2, 4, 50257])\n",
      "输出数据：\n",
      " tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试GPT模型的输出\n",
    "torch.manual_seed(123)\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "# 创建两个测试文本\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "# 对文本进行分词并转化为token ID\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "\n",
    "# 初始化GPT模型\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 输入测试文本，获取模型输出\n",
    "out = model(batch)\n",
    "print(\"输入数据:\\n\", batch)\n",
    "# 输出维度是[2,4,50257]，因为传入两个文本，每个文本有4个词元，\n",
    "# 50257是词汇表中的词元数量，每个数值表示对下一个词的预测分数\n",
    "print(\"\\n输出数据维度:\", out.shape)\n",
    "print(\"输出数据：\\n\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5743b",
   "metadata": {},
   "source": [
    "实验任务24：使用初始化GPT模型生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d642fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成文本函数的参数含义：\n",
    "# model是我们构建的GPT模型\n",
    "# idx是输入文本\n",
    "# max_new_tokens是生成文本的最大长度\n",
    "# contex_size是GPT模型支持的上下文长度\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx是输入文本的索引数组，形状为(batch, n_tokens)\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 如果当前输入文本超出大模型支持的上下文长度，则进行截断\n",
    "        # 例如，如果大模型支持的上下文长度为5，此时文本长度为10，\n",
    "        # 则只有最后5个词元被用于大模型的输入\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # 得到大模型的预测输出\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # 只关注最后一个token输出的内容\n",
    "        # 维度从(batch, n_tokens, vocab_size) 变为 (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # 通过softmax函数获取预测概率 (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1) \n",
    "\n",
    "        # 将概率最大的token作为预测结果  (batch, 1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "        # 将预测结果添加到输入文本的后面进行下一轮预测 (batch, n_tokens+1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1) \n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5073c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n",
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "# 构造输入文本，尝试构造不同的文本\n",
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "# 用到了上一次实验中初始化的模型\n",
    "model.eval() # 让模型处于验证模式，在生成文本时禁用dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n",
    "# 解码并输出生成的文本\n",
    "decoded_text = tokenizer.decode(out[0].tolist())\n",
    "# 模型生成了无意义的内容，因为只随机初始化GPT模型的权重，还没有对模型进行训练\n",
    "print(decoded_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc300893",
   "metadata": {},
   "source": [
    "实验任务25：实现文本到tokenID的转换函数和tokenID到文本的转换函数，并测试初始化模型的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7763c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "# 为了方便训练缩小上下文长度\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 词汇表大小\n",
    "    \"context_length\": 256, # 缩短上下文长度 (原长度: 1024)\n",
    "    \"emb_dim\": 768,        # 嵌入维度\n",
    "    \"n_heads\": 12,         # 注意力头数量\n",
    "    \"n_layers\": 12,        # 层数\n",
    "    \"drop_rate\": 0.1,      # drouput率\n",
    "    \"qkv_bias\": False      # 查询-键-值的偏置\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # 在模型推理时禁用dropout\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 增加批量维度\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 去掉批量维度\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b732c1",
   "metadata": {},
   "source": [
    "课内练习：尝试初始化更大的GPT模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395b9a3",
   "metadata": {},
   "source": [
    "实验任务26：以短篇小说作为数据集，使用第二节课实现的数据加载器生成训练数据和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15e3f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# 读取短篇小说文本数据\n",
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98531cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入第二节课实现的数据加载器\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # 初始化分词器\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # 创建数据集\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # 创建数据加载器\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89a9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照9：1的比例划分训练集和验证集\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# 实现训练集加载器\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "# 实现验证集加载器\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef82a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 测试训练数据加载器和验证数据加载器\n",
    "print(\"Train loader:\") # 总共生成9个批次的训练数据\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")# 总共生成1个批次的验证数据\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a038433",
   "metadata": {},
   "source": [
    "实验任务27：实现交叉熵损失函数，实现GPT模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f66e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现给定批次数据的交叉熵计算\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# 实现所有批次数据的交叉熵计算\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果批次数超过数据加载器中的批次数，减少批次数\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309de01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现模型训练函数\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 初始化训练损失和验证损失列表\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs): # num_epochs是训练迭代次数\n",
    "        model.train()  # 将模型设置为训练模式\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 重置损失梯度\n",
    "            # 计算该批次训练数据的损失\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 计算损失的梯度\n",
    "            optimizer.step() # 根据损失梯度更新模型权重\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # 可选的评估步骤\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每次迭代后输出生成的文本\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "# 评估模型在所有数据上的训练损失和验证损失\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # 调整输出格式\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a61e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# 如果有GPU，在GPU上训练模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "# 设置模型优化器，这里采用Pytorch提供的Adam优化器，设置其学习率和权重衰减参数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10 # 训练迭代次数\n",
    "# 执行模型训练\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad488dca",
   "metadata": {},
   "source": [
    "实验任务28：画图显示训练集损失和验证集损失，观察损失随训练轮数的变化，说明存在什么问题？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235fef1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 绘制训练损失和验证损失\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    # X轴显示整数\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  \n",
    "\n",
    "    ax2 = ax1.twiny() \n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) \n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout() \n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87712833",
   "metadata": {},
   "source": [
    "课后实验任务：在一个中文数据集上实现GPT模型预训练，并使用它生成文本"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
